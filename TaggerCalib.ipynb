{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is currently the best code for calibrating the tagger timing and saving the offsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A (Possible) Code for Calibrating the Tagger Timing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the tools we'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.16/00\n"
     ]
    }
   ],
   "source": [
    "import Acqu as aq\n",
    "import AcquDetector as aqdet\n",
    "import ROOT\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "from rootpy.plotting import histogram, Hist2D, Hist, Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data to be analyzed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mk2 Data\n"
     ]
    }
   ],
   "source": [
    "inFile = \"/scratch/2019-05_Timepix/Timepix_33.dat\"\n",
    "aq.openFile(inFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the detector file for the Tagger:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taggerNewer.json\n"
     ]
    }
   ],
   "source": [
    "aqdet.LoadDetectors([\"taggerNewer.json\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up histograms for each of the channels, and then fill them with tagger times from our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events Processed: 5000\n",
      "Events Processed: 10000\n",
      "Events Processed: 15000\n",
      "Events Processed: 20000\n",
      "Events Processed: 25000\n",
      "Events Processed: 30000\n",
      "Events Processed: 35000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cadcea0b41ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Events Processed: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meventNo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0maq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunFunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplotCalTagger\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500000\u001b[0m\u001b[0;34m)\u001b[0m               \u001b[0;31m# run this process over 500000 events\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/AcquPy/Acqu.pyc\u001b[0m in \u001b[0;36mrunFunction\u001b[0;34m(function, minEvents, maxEvents)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0meventNo\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessEvent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meventNo\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mminEvents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meventNo\u001b[0m\u001b[0;34m>=\u001b[0m\u001b[0mmaxEvents\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxEvents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-cadcea0b41ce>\u001b[0m in \u001b[0;36mplotCalTagger\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m                     \u001b[0;31m# for each tagger time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mchan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"channel\"\u001b[0m\u001b[0;34m]\u001b[0m                 \u001b[0;31m# get the current channel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mtaggTime\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchan\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m             \u001b[0;31m# put that time in the histogram for the current channel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meventNo\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m                          \u001b[0;31m# print a processing statement every 5000 events\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "taggerChannels = aqdet.Channels[\"Tagger\"]     # number of channels in the tagger (368)\n",
    "\n",
    "global taggTime\n",
    "taggTime = [None]*taggerChannels                # set up an array of 368 histograms to fill      \n",
    "\n",
    "for i in range(taggerChannels):               # for each tagger channel\n",
    "    taggTime[i] = Hist(1300,-500,800)           # set up a histogram for that tagger channel\n",
    "\n",
    "def plotCalTagger():\n",
    "    data = aqdet.Calibrate(aq.adcArray)              # calibrate the data\n",
    "    taggerTimes = aqdet.Arrays[\"Tagger\"][\"Time\"]     # get the tagger times\n",
    "    \n",
    "    for dat in taggerTimes:                          # for each data point\n",
    "        for time in dat[\"Time\"]:                     # for each tagger time\n",
    "            chan = dat[\"channel\"]                 # get the current channel        \n",
    "            taggTime[chan].Fill(time)             # put that time in the histogram for the current channel\n",
    "                    \n",
    "    if(aq.eventNo%5000==0):                          # print a processing statement every 5000 events\n",
    "        print(\"Events Processed: \"+str(aq.eventNo))\n",
    "    \n",
    "aq.runFunction(plotCalTagger,0,500000)               # run this process over 500000 events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the data for the tagger channels and apply a gaussian fit (with an offset) to them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tagger_times = ROOT.TFile(\"tagger_times.root\",\"RECREATE\")     # create a root file to put all the histograms into\n",
    "\n",
    "myFit = ROOT.TF1(\"myFit\",\"gaus(0)+pol0(3)\")                   # make a gaussian fit with an offset/background\n",
    "myFit.SetParNames(\"constant\",\"mean\",\"stdev\",\"background\")     # label the parameters\n",
    "\n",
    "badFitChannels = []      # set up an array to remember the empty or near empty histograms\n",
    "\n",
    "con = [None]*taggerChannels           # set up an array for the constant value\n",
    "peak = [None]*taggerChannels          # set up an array for the peak locations\n",
    "sigma = [None]*taggerChannels         # set up an array for the standard deviations of the peaks\n",
    "bgLevel = [None]*taggerChannels       # set up an array for the background levels\n",
    "\n",
    "sig = 1.1    # initialize a standard deviation value to try\n",
    "bg = 100     # initialize a background value to try\n",
    "\n",
    "for i in range(taggerChannels):              # for each channel in the tagger    \n",
    "    taggTime[i].SetTitle(\"Channel \"+str(i))    # set the title for the histogram              \n",
    "    \n",
    "    if(taggTime[i].GetEntries()>10):                         # if the histogram has entries\n",
    "        binmax = taggTime[i].GetMaximumBin()                 # find the maximum number of entries in a bin\n",
    "        pk = taggTime[i].GetXaxis().GetBinCenter(binmax)     # find the bin corresponding to the max\n",
    "        \n",
    "        myFit.SetParameter(1,pk)          # try a peak value near the fullest bin\n",
    "        myFit.SetParameter(2,sig)         # try this standard deviation value for the fit       \n",
    "        myFit.SetParameter(3,bg)          # try this background value for the fit\n",
    "        \n",
    "        taggTime[i].Fit(\"myFit\",\"S\",\"\",-300,600)    # fit the histogram with a gaussian\n",
    "        \n",
    "        con[i] = taggTime[i].GetFunction(\"myFit\").GetParameter(\"constant\")           # save the constant value\n",
    "        peak[i] = taggTime[i].GetFunction(\"myFit\").GetParameter(\"mean\")              # save the peak position\n",
    "        sigma[i] = taggTime[i].GetFunction(\"myFit\").GetParameter(\"stdev\")            # save the standard deviation\n",
    "        bgLevel[i] = taggTime[i].GetFunction(\"myFit\").GetParameter(\"background\")     # save the background level\n",
    "        \n",
    "        # check to make sure we're getting the fit we want\n",
    "        if(ROOT.gMinuit.fCstatu!=\"CONVERGED \" or not(120<peak[i]<160) or not(0<sigma[i]<4) or bgLevel[i]<0 or con[i]<0):  \n",
    "            print(\"Channel \"+str(i)+\" fit has failed.\")     # if this is printed, see OldTaggerCalib.ipynb for possible while loop\n",
    "            badFitChannels.append(i)                        # note that this channel was not fit\n",
    "        \n",
    "        sig = sigma[i]       # try using this sigma value for the next channel\n",
    "        bg = bgLevel[i]      # try using this background value for the next channel\n",
    "       \n",
    "    else:       # if the histogram is empty                                     \n",
    "        print(\"Histogram \"+str(i)+\" is empty (has \"+str(taggTime[i].GetEntries())+\" entries).\")    # then say so \n",
    "        badFitChannels.append(i)               # note that this channel was not fit\n",
    "     \n",
    "    taggTime[i].Write(\"tagger_times\")     # write the histogram to a root file for viewing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shifting the histograms so that the peak of each is at zero (likely not needed - but a good visual tool):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tagger_calib = ROOT.TFile(\"tagger_calib.root\",\"RECREATE\")    # create a root file to put all the histograms into\n",
    "\n",
    "histos_calib = [None]*taggerChannels            # set up an array of 368 histograms to fill\n",
    "\n",
    "for chan in range(taggerChannels):              # for each channel in the tagger\n",
    "    histos_calib[chan] = Hist(1300,-500,800)    # create a histogram            \n",
    "    if (peak[chan]!=None):                      # so long as there is a peak value saved\n",
    "        histos_calib[chan] = Hist(1300,int(-500-peak[chan]),int(800-peak[chan]))      # create a histogram shifted back by the value of the peak      \n",
    "        for tbin in range(1300):                                                      # for each bin in that channel's data\n",
    "            histos_calib[chan].SetBinContent(tbin,histos[chan].GetBinContent(tbin))   # give the bin that channel's data, now shifted back by the peak value\n",
    "     \n",
    "    histos_calib[chan].SetTitle(\"Channel \"+str(chan))    # set the title for the histogram\n",
    "    \n",
    "    histos_calib[chan].Write(\"tagger_calib\")             # write the histogram to a root file for viewing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we must import the json file, change the channel offset values, and then save the array again as a new json file. The location of the peak must first be divided by the scale parameter, since the offset values in the setup file are unscaled values (not converted into ns). This value is then added to the current offset value, since we're fitting the peak to the calibrated data. Note that the channels with empty histograms will not rewrite their offset values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibData = json.load(open(\"taggerNewer.json\"), object_pairs_hook=OrderedDict)     # load the tagger calibration data and keep its original ordering\n",
    "\n",
    "chan = 0                                    # starting at channel 0\n",
    "for chanData in calibData[\"channels\"]:      # for each tagger channel's data\n",
    "    if(chan not in badFitChannels):         # so long as the histogram has data fitted\n",
    "        chanData[\"offset\"][0] += peak[chan]/chanData[\"scale\"][0]      # change the offset value to the correct one\n",
    "    chan+=1                                 # move on to the next channel\n",
    "\n",
    "json.dump(calibData, open(\"taggerWithOffsets.json\", \"w\"), indent = 2)              # write the changed data to a new json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
